# ========================================
# Batch Layer Environment Variables
# ========================================
# Copy this file to .env and update with your actual values
# ========================================

# TMDB API Configuration
# Get your API key from: https://www.themoviedb.org/settings/api
TMDB_API_KEY=your_tmdb_api_key_here
TMDB_BASE_URL=https://api.themoviedb.org/3
TMDB_RATE_LIMIT=4.0
TMDB_RETRY_ATTEMPTS=3
TMDB_RETRY_BACKOFF=2.0

# HDFS Configuration
# Namenode connection (use service name for Docker, localhost for local)
HDFS_NAMENODE=hdfs://namenode:8020
HDFS_REPLICATION=3
HDFS_BLOCK_SIZE=128m
HDFS_PATH_BRONZE=/data/bronze
HDFS_PATH_SILVER=/data/silver
HDFS_PATH_GOLD=/data/gold

# Spark Configuration
# Master URL (use service name for Docker, local[*] for local)
SPARK_MASTER_URL=spark://spark-master:7077
SPARK_APP_NAME=movie-analytics-batch
SPARK_EXECUTOR_MEMORY=4g
SPARK_EXECUTOR_CORES=2
SPARK_DRIVER_MEMORY=2g

# MongoDB Configuration
# Format: mongodb://username:password@host:port/database?authSource=admin
MONGODB_CONNECTION_STRING=mongodb://admin:password@mongo:27017/moviedb?authSource=admin
MONGODB_DATABASE=moviedb

# Batch Layer Configuration
BATCH_INTERVAL_HOURS=4
BRONZE_RETENTION_DAYS=90
SILVER_RETENTION_DAYS=730
GOLD_RETENTION_DAYS=1825

# Airflow Configuration
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW__CORE__FERNET_KEY=your_fernet_key_here
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
# Generate a strong random secret key
AIRFLOW__WEBSERVER__SECRET_KEY=your_secret_key_here

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Environment
# Options: development, docker, production
ENVIRONMENT=docker
