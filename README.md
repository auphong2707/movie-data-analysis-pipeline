# Movie Data Analytics Pipeline - Lambda Architecture

A production-ready big data analytics pipeline implementing **Lambda Architecture** to analyze TMDB movie data for real-time sentiment tracking, trend prediction, and comprehensive analytics.

## ğŸ“‹ Table of Contents

- [Project Overview](#-project-overview)
- [Architecture](#-architecture)
- [Technology Stack](#-technology-stack)
- [Core Features](#-core-features)
- [Data Pipeline Architecture](#-data-pipeline-architecture)
- [Project Structure](#-project-structure)
- [Quick Start](#-quick-start)
- [Implementation Status](#-implementation-status)
- [Documentation](#-documentation)
- [Deployment](#-deployment)
- [Monitoring & Operations](#-monitoring--operations)
- [Contributing](#-contributing)
- [License](#-license)

## ğŸ¯ Project Overview

### Business Problems Solved

1. **Movie Popularity & Trend Prediction**
   - Analyze time-series signals (popularity, vote counts, rating velocity)
   - Detect rising/declining titles in real-time
   - Forecast short-term demand using historical patterns

2. **Genre-Based Sentiment Insights**
   - Real-time sentiment scoring on new reviews
   - Historical sentiment trends by genre, year, and popularity tier
   - Track audience perception shifts across blockbuster vs. niche films

3. **Recommendation System**
   - Content-based filtering using metadata (genres, cast, keywords)
   - Re-rank by current trends and sentiment scores
   - Combine historical accuracy with real-time relevance

### Data Scope

- **Source**: The Movie Database (TMDB) API
- **Volume**: ~50K movies, 100K+ reviews/month
- **Languages**: English-language content
- **Update Frequency**: 
  - Batch Layer: Every 4 hours (historical accuracy)
  - Speed Layer: <5 minute latency (real-time freshness)
- **API Rate Limit**: 4 requests/second (TMDB constraint)

## ğŸ—ï¸ Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         TMDB API                    â”‚
                    â”‚    (4 requests/second limit)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚              â”‚
                                 â”‚              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   BATCH LAYER     â”‚  â”‚   SPEED LAYER    â”‚
                    â”‚ (Historical Data) â”‚  â”‚ (Real-time Data) â”‚
                    â”‚                   â”‚  â”‚                  â”‚
                    â”‚ â€¢ HDFS Storage    â”‚  â”‚ â€¢ Kafka Streamingâ”‚
                    â”‚ â€¢ Spark Batch     â”‚  â”‚ â€¢ Cassandra      â”‚
                    â”‚ â€¢ Airflow         â”‚  â”‚ â€¢ Spark Streamingâ”‚
                    â”‚                   â”‚  â”‚                  â”‚
                    â”‚ Every 4 hours     â”‚  â”‚ 5-min windows    â”‚
                    â”‚ Complete accuracy â”‚  â”‚ Low latency      â”‚
                    â”‚ (> 48 hours old)  â”‚  â”‚ (â‰¤ 48 hours old) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚              â”‚
                                 â”‚              â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  SERVING LAYER     â”‚
                              â”‚                    â”‚
                              â”‚ â€¢ MongoDB (merged  â”‚
                              â”‚   batch + speed    â”‚
                              â”‚   views)           â”‚
                              â”‚ â€¢ FastAPI REST API â”‚
                              â”‚ â€¢ Apache Superset  â”‚
                              â”‚ â€¢ Grafana          â”‚
                              â”‚                    â”‚
                              â”‚ Query-time merge   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Lambda Architecture Components

The pipeline implements Nathan Marz's Lambda Architecture pattern with three distinct layers:

**Batch Layer**: Processes complete historical datasets for accuracy (>48 hours old)
- Reprocessing capability for corrections
- Complete data accuracy
- Higher latency acceptable

**Speed Layer**: Processes recent data for low latency (â‰¤48 hours old)  
- Real-time incremental updates
- Approximations acceptable
- Sub-5-minute latency

**Serving Layer**: Merges batch accuracy with speed freshness
- 48-hour cutoff merge strategy
- Unified query interface
- Best of both worlds

## ğŸ› ï¸ Technology Stack

### Batch Layer Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Orchestration** | Apache Airflow | Schedule & manage batch jobs (4-hour intervals) |
| **Processing** | Apache Spark (Batch) | Transform data through Bronze â†’ Silver â†’ Gold |
| **Storage** | HDFS (Hadoop 3.x) | Distributed storage for all data layers |
| **Data Quality** | Great Expectations | Validate data at each transformation stage |

### Speed Layer Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Streaming** | Apache Kafka | Message queue for real-time data ingestion |
| **Processing** | Spark Structured Streaming | Process data in 5-minute windows |
| **Storage** | Apache Cassandra | Low-latency writes with 48h TTL auto-expiration |
| **Schema** | Confluent Schema Registry | Avro schema management for Kafka topics |

### Serving Layer Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Database** | MongoDB | Unified storage for batch + speed views |
| **API** | FastAPI | High-performance async REST API endpoints |
| **Caching** | Redis | Response caching for frequently accessed data |
| **BI Dashboards** | Apache Superset | Business intelligence and analytics dashboards |
| **Monitoring** | Grafana | Real-time system monitoring and alerting |

### Cross-Cutting Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Metadata Management** | DataHub | Data catalog, lineage tracking, governance |
| **Orchestration** | Kubernetes | Container orchestration for all services |
| **Development** | Docker Compose | Lightweight local development environment |
| **Monitoring** | Prometheus | Metrics collection and alerting |
| **Version Control** | Git | Source code management |

## ğŸ¨ Core Features

### Real-Time Analytics
- **Sentiment Analysis**: VADER-based sentiment scoring on movie reviews
- **Trending Detection**: Identify hot movies based on velocity and acceleration
- **Live Statistics**: Real-time aggregations of ratings, votes, and popularity

### Historical Analysis
- **Genre Analytics**: Comprehensive statistics by genre, year, and tier
- **Temporal Trends**: Year-over-year and seasonal pattern analysis
- **Actor Networks**: Collaboration graphs using GraphX
- **Revenue Analysis**: Budget vs. revenue performance tracking

### Query Capabilities
- **Fast Queries**: <100ms p95 latency through MongoDB + Redis caching
- **Fresh Data**: 5-minute freshness from speed layer
- **Deep History**: 5-year historical data from batch layer
- **Flexible Search**: Full-text search with multiple filter dimensions

### Data Quality
- **Schema Validation**: Automated validation at each layer
- **Deduplication**: Intelligent duplicate removal by movie_id
- **Completeness Checks**: >95% data quality target
- **Anomaly Detection**: Statistical outlier identification

## ğŸ“Š Data Pipeline Architecture

### Batch Layer Flow

```
TMDB API (scheduled extraction)
    â†“ (Airflow DAG - every 4 hours)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BRONZE LAYER (HDFS)           â”‚
â”‚  â€¢ Raw JSON â†’ Parquet                 â”‚
â”‚  â€¢ Partition: /year/month/day/hour    â”‚
â”‚  â€¢ Retention: 90 days                 â”‚
â”‚  â€¢ No transformations (immutable)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“ (Spark Batch Job)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SILVER LAYER (HDFS)           â”‚
â”‚  â€¢ Deduplication by movie_id          â”‚
â”‚  â€¢ Schema validation & enrichment     â”‚
â”‚  â€¢ Genre/cast joins                   â”‚
â”‚  â€¢ Historical sentiment analysis      â”‚
â”‚  â€¢ Partition: /year/month/genre       â”‚
â”‚  â€¢ Retention: 2 years                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“ (Spark Aggregations)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          GOLD LAYER (HDFS)            â”‚
â”‚  â€¢ Aggregations by genre/year/tier    â”‚
â”‚  â€¢ Trend scores (7d, 30d, 90d)        â”‚
â”‚  â€¢ Popularity metrics                 â”‚
â”‚  â€¢ Partition: /metric_type/year/month â”‚
â”‚  â€¢ Retention: 5 years                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“ (Export to Serving)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MONGODB (Batch Views)            â”‚
â”‚  â€¢ Collection: batch_views            â”‚
â”‚  â€¢ Updated every 4 hours              â”‚
â”‚  â€¢ Indexed for fast queries           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Speed Layer Flow

```
TMDB API (real-time stream)
    â†“ (Kafka Producer - streaming)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          KAFKA TOPICS                 â”‚
â”‚  â€¢ movie.reviews (new reviews)        â”‚
â”‚  â€¢ movie.ratings (new ratings)        â”‚
â”‚  â€¢ movie.metadata (updates)           â”‚
â”‚  â€¢ Replication factor: 3              â”‚
â”‚  â€¢ Retention: 7 days                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“ (Spark Structured Streaming)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      REAL-TIME PROCESSING             â”‚
â”‚  â€¢ 5-minute tumbling windows          â”‚
â”‚  â€¢ Real-time sentiment (VADER)        â”‚
â”‚  â€¢ Incremental aggregations           â”‚
â”‚  â€¢ Hot movie detection (velocity)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“ (Write to Cassandra)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      CASSANDRA (Speed Views)          â”‚
â”‚  â€¢ Table: speed_views                 â”‚
â”‚  â€¢ TTL: 48 hours (auto-expire)        â”‚
â”‚  â€¢ Partition: (movie_id, hour)        â”‚
â”‚  â€¢ Replication factor: 3              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“ (Periodic sync - 5 min)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MONGODB (Speed Views)            â”‚
â”‚  â€¢ Collection: speed_views            â”‚
â”‚  â€¢ Synced every 5 minutes             â”‚
â”‚  â€¢ TTL index: 48 hours                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Serving Layer Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB    â”‚         â”‚   MongoDB    â”‚
â”‚ batch_views  â”‚         â”‚ speed_views  â”‚
â”‚ (historical) â”‚         â”‚ (last 48h)   â”‚
â”‚ (>48h old)   â”‚         â”‚ (â‰¤48h old)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Query Router  â”‚  â€¢ 48-hour cutoff logic
        â”‚ & Merger      â”‚  â€¢ Merge batch + speed
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ Deduplicate results
                â”‚
                â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Redis Cache  â”‚  â€¢ 5-15 minute TTL
        â”‚               â”‚  â€¢ Frequently accessed data
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   FastAPI     â”‚  â€¢ REST API endpoints
        â”‚               â”‚  â€¢ <100ms p95 latency
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ Authentication & rate limiting
                â”‚
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ Supersetâ”‚            â”‚    Grafana    â”‚
â”‚Dashboardsâ”‚            â”‚  Monitoring   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
movie-data-analysis-pipeline/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ docker-compose.yml                 # Local development setup
â”‚
â”œâ”€â”€ config/                           # Configuration files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                     # Application configuration
â”‚   â”œâ”€â”€ airflow_config.py             # Airflow DAG configs
â”‚   â”œâ”€â”€ kafka_config.py               # Kafka settings
â”‚   â”œâ”€â”€ kafka_setup.py                # Kafka topic initialization
â”‚   â”œâ”€â”€ iceberg_config.py             # Apache Iceberg configs
â”‚   â””â”€â”€ schemas.py                    # Data schemas (Avro, Parquet)
â”‚
â”œâ”€â”€ layers/                           # Lambda Architecture layers
â”‚   â”œâ”€â”€ batch_layer/                  # Historical processing
â”‚   â”‚   â”œâ”€â”€ README.md                 # Detailed batch layer docs
â”‚   â”‚   â”œâ”€â”€ airflow_dags/            # Orchestration workflows
â”‚   â”‚   â”œâ”€â”€ spark_jobs/              # Bronze â†’ Silver â†’ Gold
â”‚   â”‚   â”œâ”€â”€ master_dataset/          # TMDB ingestion
â”‚   â”‚   â”‚   â””â”€â”€ ingestion.py         # Raw data extraction
â”‚   â”‚   â”œâ”€â”€ batch_views/             # Pre-computed views
â”‚   â”‚   â”œâ”€â”€ config/                  # Spark/HDFS configs
â”‚   â”‚   â””â”€â”€ tests/                   # Unit tests
â”‚   â”‚
â”‚   â”œâ”€â”€ speed_layer/                 # Real-time processing
â”‚   â”‚   â”œâ”€â”€ README.md                # Detailed speed layer docs
â”‚   â”‚   â”œâ”€â”€ kafka_producers/         # Data streaming
â”‚   â”‚   â”‚   â””â”€â”€ tmdb_stream_producer.py
â”‚   â”‚   â”œâ”€â”€ streaming_jobs/          # Spark Structured Streaming
â”‚   â”‚   â”œâ”€â”€ cassandra_views/         # Speed view schemas
â”‚   â”‚   â”œâ”€â”€ connectors/              # Cassandra â†’ MongoDB sync
â”‚   â”‚   â”œâ”€â”€ config/                  # Kafka/Cassandra configs
â”‚   â”‚   â””â”€â”€ tests/                   # Unit tests
â”‚   â”‚
â”‚   â””â”€â”€ serving_layer/               # Query interface
â”‚       â”œâ”€â”€ README.md                # Detailed serving layer docs
â”‚       â”œâ”€â”€ api/                     # FastAPI REST endpoints
â”‚       â”‚   â””â”€â”€ main.py              # API entry point
â”‚       â”œâ”€â”€ query_engine/            # View merger logic
â”‚       â”œâ”€â”€ mongodb/                 # Database layer
â”‚       â”œâ”€â”€ visualization/           # Superset & Grafana
â”‚       â”œâ”€â”€ config/                  # API/MongoDB configs
â”‚       â””â”€â”€ tests/                   # API & integration tests
â”‚
â”œâ”€â”€ kubernetes/                       # Production deployment
â”‚   â”œâ”€â”€ README.md                    # Kubernetes deployment guide
â”‚   â”œâ”€â”€ namespace.yaml               # Namespace definition
â”‚   â”œâ”€â”€ configmap.yaml              # Configuration & secrets
â”‚   â”œâ”€â”€ kafka.yaml                  # Kafka cluster
â”‚   â”œâ”€â”€ minio.yaml                  # Object storage (HDFS alternative)
â”‚   â”œâ”€â”€ mongodb.yaml                # MongoDB replica set
â”‚   â”œâ”€â”€ spark.yaml                  # Spark cluster
â”‚   â”œâ”€â”€ applications.yaml           # Application deployments
â”‚   â”œâ”€â”€ monitoring.yaml             # Prometheus & Grafana
â”‚   â”œâ”€â”€ visualization.yaml          # Apache Superset
â”‚   â””â”€â”€ deploy.sh                   # Automated deployment script
â”‚
â”œâ”€â”€ docs/                            # Additional documentation
â”‚   â””â”€â”€ Movie Data Analysis Pipeline.drawio  # Architecture diagrams
â”‚
â””â”€â”€ tests/                           # Integration tests
    â””â”€â”€ (test files)
```

## ğŸš€ Quick Start

> **âœ¨ NEW: Unified Setup Available!**  
> The batch and speed layers are now combined into a single setup at the project root.  
> See [QUICKSTART.md](QUICKSTART.md) for the fastest way to get started, or [SETUP.md](SETUP.md) for detailed instructions.

### Prerequisites

- **Docker Desktop** or **Docker Engine** (version 20.10+)
- **Docker Compose** (version 1.29+)
- **At least 8GB RAM** allocated to Docker
- **TMDB API Key** (free from [themoviedb.org](https://www.themoviedb.org/settings/api))

### Unified Setup (Recommended)

The unified setup runs both Batch Layer and Speed Layer with a single command:

1. **Clone the Repository**
   ```bash
   git clone https://github.com/auphong2707/movie-data-analysis-pipeline.git
   cd movie-data-analysis-pipeline
   ```

2. **Configure Environment Variables**
   ```bash
   # Copy template and add your TMDB API key
   cp .env.example .env
   nano .env  # Set TMDB_API_KEY=your_key_here
   ```

3. **Start All Services**
   ```bash
   # Start complete infrastructure (Batch + Speed layers)
   docker-compose up -d
   
   # Verify all services are running
   docker-compose ps
   ```

4. **Access Web Interfaces**
   - **Airflow (Batch Layer)**: http://localhost:8088 (admin/admin)
   - **MinIO Console**: http://localhost:9001 (minioadmin/minioadmin)
   - **Schema Registry**: http://localhost:8081

For detailed instructions and troubleshooting, see:
- **Quick Reference**: [QUICKSTART.md](QUICKSTART.md)
- **Complete Setup Guide**: [SETUP.md](SETUP.md)

### Running the Pipeline

**Batch Layer** (historical data processing):
```bash
# Trigger Airflow DAG manually or wait for scheduled run
# Access Airflow UI at http://localhost:8088
```

**Speed Layer** (real-time streaming):
```bash
# Automatically starts with docker-compose
# View logs: docker-compose logs -f tmdb-producer sentiment-stream
```

**Query Results**:
```bash
# Connect to MongoDB
docker exec -it mongodb mongosh -u admin -p password --authenticationDatabase admin

# View merged data
use moviedb
db.batch_views.find().limit(5)  # Historical (>48h)
db.speed_views.find().limit(5)  # Recent (â‰¤48h)
```

For complete instructions, see [SETUP.md](SETUP.md).

## âœ… Implementation Status

### Phase 1: Setup & Planning - âœ… COMPLETED
- [x] Lambda Architecture design
- [x] Directory structure (`layers/batch_layer`, `layers/speed_layer`, `layers/serving_layer`)
- [x] Documentation (12+ markdown files)
- [x] Template code for all layers

### Phase 2: Batch Layer - ğŸ”² TODO
- [ ] Deploy HDFS cluster (3 datanodes + namenode)
- [ ] Implement TMDB â†’ HDFS ingestion
- [ ] Create Airflow DAGs (batch orchestration)
- [ ] Bronze â†’ Silver transformations (deduplication, validation)
- [ ] Silver â†’ Gold aggregations (genre, trends, ratings)
- [ ] Sentiment analysis (batch processing)
- [ ] Export batch views to MongoDB

### Phase 3: Speed Layer - ğŸ”² TODO
- [ ] Deploy Kafka cluster (3 brokers + Zookeeper)
- [ ] Deploy Schema Registry (Avro schemas)
- [ ] Implement Kafka producers (real-time)
- [ ] Deploy Cassandra cluster (3 nodes, 48h TTL)
- [ ] Spark Structured Streaming jobs
- [ ] Real-time sentiment analysis
- [ ] Write to Cassandra speed views

### Phase 4: Serving Layer - ğŸ”² TODO
- [ ] Deploy MongoDB (materialized views)
- [ ] Implement FastAPI REST API
- [ ] View merger (batch + speed merge logic)
- [ ] Redis caching layer
- [ ] Apache Superset dashboards
- [ ] Grafana monitoring
- [ ] API authentication & rate limiting

### Phase 5: Integration & Testing - ğŸ”² TODO
- [ ] End-to-end integration
- [ ] 48-hour merge strategy implementation
- [ ] Performance benchmarking
- [ ] Unit & integration tests
- [ ] Data quality validation

### Phase 6: Production Deployment - ğŸ”² TODO
- [ ] Kubernetes manifests (all services)
- [ ] Persistent volumes (HDFS storage)
- [ ] Monitoring & alerting setup
- [ ] Security hardening
- [ ] Deployment automation

## ğŸ“š Documentation

### Architecture Documentation
- **[Batch Layer Guide](layers/batch_layer/README.md)**: Complete guide to HDFS storage, Spark batch jobs, Airflow DAGs, and Bronze â†’ Silver â†’ Gold transformations
- **[Speed Layer Guide](layers/speed_layer/README.md)**: Kafka streaming, Spark Structured Streaming, Cassandra setup, and real-time processing
- **[Serving Layer Guide](layers/serving_layer/README.md)**: FastAPI endpoints, MongoDB schema, query merger logic, and caching strategies
- **[Kubernetes Deployment](kubernetes/README.md)**: Production deployment guide with monitoring, scaling, and troubleshooting

### Presentation Materials
- **[First Presentation](First%20Presentation%2028accfcd991180e7889cd9dc5e83ca02.md)**: Project overview, business problems, and architecture explanation

### Technical Specifications
- **Configuration Files**: See `config/` directory for all service configurations
- **API Documentation**: Interactive docs at `/docs` endpoint when API is running
- **Architecture Diagrams**: See `docs/Movie Data Analysis Pipeline.drawio`

## ğŸš¢ Deployment (Dummy, didn't work yet)

### Docker Compose (Development)

Best for local development and testing:

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Clean up (including volumes)
docker-compose down -v
```

### Kubernetes (Production) (Dummy, didn't work yet)

Production-ready deployment with high availability:

```bash
# Navigate to kubernetes directory
cd kubernetes

# Deploy complete stack
./deploy.sh deploy

# Check deployment status
kubectl get pods -n movie-analytics

# Access services via port forwarding
kubectl port-forward -n movie-analytics service/movie-api-service 8000:8000
kubectl port-forward -n movie-analytics service/grafana-service 3000:3000
kubectl port-forward -n movie-analytics service/superset-service 8088:8088

# Clean up
./deploy.sh clean
```

See [kubernetes/README.md](kubernetes/README.md) for detailed deployment instructions.

## ğŸ“Š Monitoring & Operations

### Key Performance Indicators

| Metric | Target | Description |
|--------|--------|-------------|
| **Batch Job Success Rate** | >99% | Percentage of successful Airflow DAG runs |
| **Batch Processing Time** | <2 hours | Time to complete Bronze â†’ Silver â†’ Gold |
| **Speed Layer Latency** | <5 minutes | End-to-end processing time for streaming |
| **API Response Time (p95)** | <100ms | 95th percentile API latency |
| **Data Quality Score** | >95% | Percentage of rows passing validation |
| **Kafka Consumer Lag** | <1000 msgs | Number of unprocessed Kafka messages |
| **Cache Hit Rate** | >70% | Percentage of requests served from cache |

### Monitoring Dashboards

**Grafana Dashboards** (http://localhost:3000):
1. **System Health**: API latency, MongoDB performance, Redis cache hit rates
2. **Data Freshness**: Batch layer updates, speed layer lag, view staleness
3. **Infrastructure**: Kafka throughput, Cassandra write rates, Spark job duration

**Apache Superset Dashboards** (http://localhost:8088):
1. **Executive Overview**: Total movies, average ratings, revenue trends
2. **Real-time Analytics**: Trending movies, recent sentiment changes
3. **Historical Analysis**: Year-over-year comparisons, genre performance

### Alerting Rules

- **Critical Alerts** (PagerDuty):
  - Batch job failures
  - Streaming job crashes
  - MongoDB/Cassandra node down
  - API p99 latency >500ms

- **Warning Alerts** (Slack):
  - Kafka consumer lag >5000 messages
  - Data quality score <90%
  - Cache hit rate <50%
  - Speed layer lag >10 minutes

### Log Aggregation (Dummy, didn't work yet)

All logs are centralized and searchable:

```bash
# Docker Compose logs
docker-compose logs -f [service_name]

# Kubernetes logs
kubectl logs -n movie-analytics -l app=[app_name] -f

# View specific service logs
kubectl logs -n movie-analytics deployment/movie-api --tail=100
```

## ğŸ§ª Testing (Dummy, didn't work yet)

### Run Tests

```bash
# Run all tests
pytest tests/

# Run specific layer tests
pytest layers/batch_layer/tests/
pytest layers/speed_layer/tests/
pytest layers/serving_layer/tests/

# Run with coverage
pytest --cov=layers --cov-report=html

# Run integration tests only
pytest -m integration
```

### Test Categories

- **Unit Tests**: Individual component functionality
- **Integration Tests**: End-to-end pipeline flows
- **Performance Tests**: Latency and throughput benchmarks
- **Data Quality Tests**: Schema validation and completeness
