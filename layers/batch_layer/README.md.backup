# Batch Layer - Historical Data Processing

## Table of Contents

- [Overview](#overview)
- [Quick Start with Docker](#quick-start-with-docker)
- [Architecture](#architecture)
- [Data Layers](#data-layers)
- [Manual Usage](#manual-usage)
- [Development](#development)

## Overview

The **Batch Layer** is responsible for processing the complete historical dataset to generate accurate, comprehensive views. It runs periodically (every 4 hours) and prioritizes accuracy over latency.

---

## Quick Start with Docker

### Prerequisites

- Docker 24.0+ and Docker Compose 2.0+
- At least 8GB RAM allocated to Docker
- 20GB free disk space
- TMDB API Key (already configured: `36bdc639ae379da0a89bfb9c556e2136`)

### Start the Stack

```bash
# Navigate to batch layer directory
cd layers/batch_layer

# Start all services (HDFS, Spark, Airflow, MongoDB)
make up

# Check service status
make ps

# View service URLs
make ui
```

### Service URLs

Once all services are running:

| Service | URL | Credentials |
|---------|-----|-------------|
| **Airflow UI** | http://localhost:8080 | admin / admin |
| **Spark Master UI** | http://localhost:8081 | - |
| **HDFS Namenode UI** | http://localhost:9870 | - |
| **Mongo Express** | http://localhost:8082 | admin / admin |
| **MongoDB** | mongodb://localhost:27017 | admin / password |

### Run Your First Pipeline

```bash
# Wait for all services to be healthy (2-3 minutes)
make health

# Create HDFS directories
make hdfs-create-dirs

# Trigger the batch pipeline DAG
make trigger-dag

# Monitor logs
make logs-airflow

# Check HDFS data
make hdfs-ls

# Query MongoDB batch_views
make mongo-query-views
```

### Common Commands

```bash
# View all available commands
make help

# Follow logs for specific services
make logs-airflow    # Airflow logs
make logs-spark      # Spark logs
make logs-hdfs       # HDFS logs
make logs-mongo      # MongoDB logs

# Run a backfill for a date range
make backfill START=2024-01-01 END=2024-01-31

# Stop all services
make down

# Stop and remove all data
make down-v

# Rebuild images
make build

# Open shells
make airflow-shell        # Airflow container
make spark-master-shell   # Spark master container
make mongo-shell          # MongoDB shell
```

### Verify Pipeline Execution

1. **Check Airflow DAG**:
   - Open http://localhost:8080
   - Login with `admin` / `admin`
   - Navigate to DAGs → `tmdb_batch_pipeline`
   - Unpause the DAG (toggle switch)
   - Click "Trigger DAG" or wait for scheduled run

2. **Monitor Spark Jobs**:
   - Open http://localhost:8081
   - Check running applications

3. **Verify HDFS Data**:
   ```bash
   make hdfs-ls
   # Should show data in /data/bronze, /data/silver, /data/gold
   ```

4. **Check MongoDB Data**:
   ```bash
   make mongo-query-views
   # Should show documents in batch_views collection
   ```

### Troubleshooting

**Services not starting?**
```bash
# Check service health
make health

# View logs for failing service
make logs

# Restart services
make restart
```

**HDFS safe mode?**
```bash
# Wait 30 seconds for HDFS to exit safe mode
docker compose -f docker-compose.batch.yml exec namenode hdfs dfsadmin -safemode get
```

**Airflow DAG not showing?**
```bash
# List DAGs
make list-dags

# Check Airflow logs
make logs-airflow
```

**Out of memory?**
```bash
# Check Docker resources
docker stats

# Reduce Spark worker memory in docker-compose.batch.yml
# SPARK_WORKER_MEMORY=2g (instead of 4g)
```

---

## Architecture

```
TMDB API (scheduled extraction)
    ↓ (Airflow DAG - every 4 hours)
┌───────────────────────────────────────┐
│         BRONZE LAYER (HDFS)           │
│  • Raw JSON → Parquet                 │
│  • Partition: /year/month/day/hour    │
│  • No transformations, immutable      │
└────────────────┬──────────────────────┘
                 ↓ (Spark Batch Job)
┌───────────────────────────────────────┐
│         SILVER LAYER (HDFS)           │
│  • Deduplication (movie_id)           │
│  • Schema validation & enrichment     │
│  • Genre/cast joins                   │
│  • Historical sentiment analysis      │
│  • Partition: /year/month/genre       │
└────────────────┬──────────────────────┘
                 ↓ (Spark Aggregations)
┌───────────────────────────────────────┐
│          GOLD LAYER (HDFS)            │
│  • Aggregations by genre/year/tier    │
│  • Trend scores (7d, 30d, 90d)        │
│  • Popularity metrics                 │
│  • Partition: /metric_type/year/month │
└────────────────┬──────────────────────┘
                 ↓ (Export to Serving)
┌───────────────────────────────────────┐
│      MONGODB (Batch Views)            │
│  • Collection: batch_views            │
│  • Updated every 4 hours              │
│  • Indexed for fast queries           │
└───────────────────────────────────────┘
```

---

## Key Characteristics

| Property | Value | Rationale |
|----------|-------|-----------|
| **Schedule** | Every 4 hours | Balances freshness vs cost |
| **Accuracy** | 100% | No approximations allowed |
| **Latency** | Hours | Acceptable for historical data |
| **Reprocessing** | Full history | Can recompute from scratch |
| **Storage** | HDFS | Distributed, fault-tolerant |
| **Retention** | Bronze: 90d, Silver: 2y, Gold: 5y | Cost vs compliance |

---

## Directory Structure

```
batch_layer/
├── README.md                    # This file
│
├── airflow_dags/               # Orchestration
│   ├── __init__.py
│   ├── batch_ingestion_dag.py  # Bronze layer ingestion
│   ├── batch_transform_dag.py  # Silver layer processing
│   ├── batch_aggregate_dag.py  # Gold layer aggregations
│   └── README.md               # DAG documentation
│
├── spark_jobs/                 # Batch processing
│   ├── __init__.py
│   ├── bronze_to_silver.py     # Cleaning & enrichment
│   ├── silver_to_gold.py       # Aggregations
│   ├── sentiment_batch.py      # Historical sentiment
│   ├── actor_networks.py       # Graph analytics
│   └── README.md               # Job documentation
│
├── master_dataset/             # Immutable raw data
│   ├── __init__.py
│   ├── ingestion.py            # TMDB → HDFS pipeline
│   ├── schema.py               # Data schemas
│   ├── partitioning.py         # Partition strategies
│   └── README.md               # Dataset documentation
│
├── batch_views/                # Pre-computed views
│   ├── __init__.py
│   ├── movie_analytics.py      # Movie-level aggregations
│   ├── genre_trends.py         # Genre-based analytics
│   ├── temporal_analysis.py    # Time-series views
│   ├── export_to_mongo.py      # MongoDB integration
│   └── README.md               # Views documentation
│
├── config/                     # Configuration
│   ├── spark_config.yaml       # Spark settings
│   ├── hdfs_config.yaml        # HDFS settings
│   └── airflow_config.yaml     # DAG settings
│
└── tests/                      # Unit tests
    ├── test_transformations.py
    ├── test_aggregations.py
    └── test_data_quality.py
```

---

## Data Layers

### Bronze Layer (Raw Data)

**Purpose**: Store immutable, raw data exactly as received from TMDB API

**Schema**:
```python
# Parquet format
bronze_schema = {
    "movie_id": "int",
    "raw_json": "string",  # Complete API response
    "api_endpoint": "string",  # movies/people/reviews
    "extraction_timestamp": "timestamp",
    "partition_year": "int",
    "partition_month": "int",
    "partition_day": "int",
    "partition_hour": "int"
}
```

**Partitioning**:
```
/bronze/movies/year=2025/month=10/day=17/hour=14/
/bronze/reviews/year=2025/month=10/day=17/hour=14/
/bronze/people/year=2025/month=10/day=17/hour=14/
```

**Retention**: 90 days (configurable)

**Implementation**: `master_dataset/ingestion.py`

---

### Silver Layer (Cleaned Data)

**Purpose**: Cleaned, validated, and enriched data ready for analytics

**Transformations**:
1. **Deduplication**: Remove duplicate movie_id entries
2. **Schema Validation**: Ensure data quality
3. **Enrichment**: 
   - Join genre names from genre_ids
   - Join cast/crew information
   - Extract keywords and production companies
4. **Sentiment Analysis**: Historical review sentiment
5. **Data Type Casting**: Proper types for all fields

**Schema**:
```python
silver_schema = {
    "movie_id": "int",
    "title": "string",
    "release_date": "date",
    "genres": "array<string>",
    "vote_average": "double",
    "vote_count": "int",
    "popularity": "double",
    "budget": "long",
    "revenue": "long",
    "runtime": "int",
    "cast": "array<struct<name:string, character:string>>",
    "crew": "array<struct<name:string, job:string>>",
    "sentiment_score": "double",  # -1 to 1
    "sentiment_label": "string",  # positive/neutral/negative
    "quality_flag": "string",  # OK/WARNING/ERROR
    "processed_timestamp": "timestamp",
    "partition_year": "int",
    "partition_month": "int",
    "partition_genre": "string"
}
```

**Partitioning**:
```
/silver/movies/year=2025/month=10/genre=action/
/silver/reviews/year=2025/month=10/genre=action/
```

**Retention**: 2 years

**Implementation**: `spark_jobs/bronze_to_silver.py`

---

### Gold Layer (Aggregated Data)

**Purpose**: Business-ready aggregations and analytics

**Aggregations**:
1. **Movie Popularity Trends**: 7-day, 30-day, 90-day rolling windows
2. **Genre Analytics**: Average ratings, revenue by genre
3. **Temporal Analysis**: Year-over-year comparisons
4. **Actor Networks**: Collaboration graphs
5. **Sentiment Trends**: Sentiment changes over time

**Views**:
```python
# Genre aggregations
genre_analytics = {
    "genre": "string",
    "year": "int",
    "month": "int",
    "total_movies": "int",
    "avg_rating": "double",
    "total_revenue": "long",
    "avg_sentiment": "double",
    "top_movies": "array<string>"
}

# Trending scores
trending_scores = {
    "movie_id": "int",
    "window": "string",  # 7d/30d/90d
    "trend_score": "double",
    "velocity": "double",  # rate of popularity change
    "computed_date": "date"
}
```

**Partitioning**:
```
/gold/genre_analytics/year=2025/month=10/
/gold/trending_scores/window=7d/year=2025/month=10/
/gold/actor_networks/year=2025/month=10/
```

**Retention**: 5 years

**Implementation**: `spark_jobs/silver_to_gold.py`

---

## Airflow DAGs

### 1. Batch Ingestion DAG (`batch_ingestion_dag.py`)

**Schedule**: Every 4 hours  
**Purpose**: Extract data from TMDB API and store in Bronze layer

```python
# DAG Structure
[start] 
  → [check_api_health]
  → [extract_movies] 
  → [extract_reviews]
  → [extract_people]
  → [validate_extraction]
  → [store_to_hdfs_bronze]
  → [update_metadata]
  → [end]
```

**Tasks**:
- `check_api_health`: Verify TMDB API availability
- `extract_*`: Parallel extraction from different endpoints
- `validate_extraction`: Check data completeness
- `store_to_hdfs_bronze`: Write Parquet to HDFS
- `update_metadata`: Update extraction logs

---

### 2. Batch Transform DAG (`batch_transform_dag.py`)

**Schedule**: 30 minutes after ingestion  
**Purpose**: Transform Bronze → Silver

```python
# DAG Structure
[start]
  → [wait_for_bronze]
  → [spark_deduplicate]
  → [spark_validate_schema]
  → [spark_enrich_data]
  → [spark_sentiment_analysis]
  → [write_to_silver]
  → [data_quality_checks]
  → [end]
```

**Spark Job**: `spark_jobs/bronze_to_silver.py`

---

### 3. Batch Aggregate DAG (`batch_aggregate_dag.py`)

**Schedule**: 1 hour after transformation  
**Purpose**: Create Gold layer views and export to MongoDB

```python
# DAG Structure
[start]
  → [wait_for_silver]
  → [spark_genre_aggregations]
  → [spark_trending_scores]
  → [spark_actor_networks]
  → [write_to_gold]
  → [export_to_mongodb]
  → [update_serving_indexes]
  → [end]
```

**Spark Jobs**: `spark_jobs/silver_to_gold.py`, `batch_views/export_to_mongo.py`

---

## Spark Jobs

### Bronze to Silver (`spark_jobs/bronze_to_silver.py`)

**Input**: HDFS Bronze layer Parquet files  
**Output**: HDFS Silver layer Parquet files

**Processing Steps**:
1. Read Bronze Parquet with pushdown filters
2. Parse raw JSON and extract fields
3. Deduplicate by movie_id (keep latest)
4. Validate schema and data types
5. Enrich with genre names, cast info
6. Run sentiment analysis on reviews
7. Add quality flags
8. Write to Silver with partitioning

**Key Optimizations**:
- Broadcast small lookup tables (genres)
- Partition by year/month/genre
- Use bucketing for frequent joins
- Z-ordering on movie_id

**Template**: See `spark_jobs/bronze_to_silver.py`

---

### Silver to Gold (`spark_jobs/silver_to_gold.py`)

**Input**: HDFS Silver layer Parquet files  
**Output**: HDFS Gold layer aggregated views

**Aggregations**:
1. **Genre Analytics**: GROUP BY genre, year, month
2. **Trending Scores**: Window functions for moving averages
3. **Actor Networks**: GraphX for collaboration graphs
4. **Temporal Analysis**: Year-over-year comparisons

**Window Functions**:
```python
# 7-day rolling average popularity
window_7d = Window.partitionBy("movie_id").orderBy("date").rowsBetween(-6, 0)
df = df.withColumn("popularity_7d_avg", avg("popularity").over(window_7d))
```

**Template**: See `spark_jobs/silver_to_gold.py`

---

## Batch Views (MongoDB Export)

### Collections in MongoDB

```javascript
// batch_views collection
{
  "_id": ObjectId("..."),
  "movie_id": 12345,
  "view_type": "genre_analytics",  // genre/trending/temporal
  "data": {
    "genre": "Action",
    "year": 2025,
    "month": 10,
    "avg_rating": 7.5,
    "total_movies": 150,
    "total_revenue": 5000000000
  },
  "computed_at": ISODate("2025-10-17T14:00:00Z"),
  "batch_run_id": "batch_2025_10_17_14"
}
```

**Indexes**:
```javascript
db.batch_views.createIndex({ "movie_id": 1, "view_type": 1 })
db.batch_views.createIndex({ "view_type": 1, "data.genre": 1, "data.year": 1 })
db.batch_views.createIndex({ "computed_at": -1 })
```

**Export Process**:
1. Read Gold layer aggregations
2. Transform to MongoDB document format
3. Bulk upsert to `batch_views` collection
4. Update indexes
5. Log export metrics

**Template**: See `batch_views/export_to_mongo.py`

---

## Docker Infrastructure

### Container Architecture

The batch layer runs in a containerized environment with the following services:

#### HDFS Cluster
- **namenode**: 1 instance (9870: Web UI, 8020: FS port)
- **datanode**: 3 instances (replicated storage)
- **Image**: `bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8`
- **Volumes**: Persistent volumes for each datanode
- **Replication**: Factor of 3 for data durability

#### Spark Cluster
- **spark-master**: 1 instance (8081: Web UI, 7077: Master port)
- **spark-worker**: 2 instances (4g memory, 2 cores each)
- **Base Image**: `apache/spark:3.5.0-python3`
- **Custom Build**: Includes Python dependencies and project code
- **Dockerfile**: `docker/spark.Dockerfile`

#### Airflow Services
- **postgres**: PostgreSQL 15 (Airflow metadata DB)
- **airflow-init**: Initializes DB, creates users, sets up connections
- **airflow-webserver**: Web UI on port 8080
- **airflow-scheduler**: DAG scheduler
- **Base Image**: `apache/airflow:2.8.0-python3.11`
- **Custom Build**: Includes batch layer dependencies
- **Dockerfile**: `docker/airflow.Dockerfile`

#### MongoDB Services
- **mongo**: MongoDB 7.0 (port 27017)
- **mongo-express**: Web UI on port 8082
- **Initialization**: Auto-creates batch_views collection with indexes
- **Script**: `docker/mongo-init.js`

### Volume Management

```yaml
volumes:
  namenode_data:      # HDFS namenode metadata
  datanode1_data:     # HDFS datanode 1 blocks
  datanode2_data:     # HDFS datanode 2 blocks
  datanode3_data:     # HDFS datanode 3 blocks
  airflow_dags:       # Airflow DAG definitions
  airflow_logs:       # Airflow execution logs
  airflow_plugins:    # Airflow plugins
  postgres_data:      # Airflow metadata
  mongo_data:         # MongoDB batch_views data
```

### Network Configuration

All services run on a bridge network `movie_batch_net`:
- DNS resolution between containers by service name
- Internal communication (HDFS, Spark, MongoDB)
- Exposed ports for external access (UIs, APIs)

### Environment Variables

Core environment variables (defined in `.env`):

```bash
# TMDB API
TMDB_API_KEY=36bdc639ae379da0a89bfb9c556e2136
TMDB_BASE_URL=https://api.themoviedb.org/3
TMDB_RATE_LIMIT=4.0

# HDFS
HDFS_NAMENODE=hdfs://namenode:8020
HDFS_REPLICATION=3

# Spark
SPARK_MASTER_URL=spark://spark-master:7077
SPARK_EXECUTOR_MEMORY=4g
SPARK_DRIVER_MEMORY=2g

# MongoDB
MONGODB_CONNECTION_STRING=mongodb://admin:password@mongo:27017/moviedb?authSource=admin

# Batch Config
BATCH_INTERVAL_HOURS=4
```

### Health Checks

All critical services have health checks:

- **namenode**: `curl http://localhost:9870`
- **spark-master**: `curl http://localhost:8080`
- **airflow-webserver**: `curl http://localhost:8080/health`
- **mongo**: `mongosh --eval "db.adminCommand('ping')"`
- **postgres**: `pg_isready -U airflow`

### Initialization Sequence

1. **postgres** starts first (Airflow metadata DB)
2. **namenode** initializes HDFS cluster
3. **datanode** instances join namenode
4. **spark-master** starts
5. **spark-worker** instances join master
6. **mongo** starts and runs `mongo-init.js`
7. **airflow-init** sets up DB, users, connections
8. **airflow-webserver** and **airflow-scheduler** start
9. **mongo-express** provides UI for MongoDB

### Resource Requirements

Minimum system requirements:
- **CPU**: 4 cores
- **RAM**: 8GB (16GB recommended)
- **Disk**: 20GB free space
- **Docker**: 24.0+
- **Docker Compose**: 2.0+

### Dockerfile Details

#### Spark Dockerfile (`docker/spark.Dockerfile`)
```dockerfile
FROM apache/spark:3.5.0-python3
# Install system dependencies
# Install Python packages (pyspark, pymongo, great-expectations)
# Copy project code
# Set PYTHONPATH and PYSPARK_PYTHON
```

#### Airflow Dockerfile (`docker/airflow.Dockerfile`)
```dockerfile
FROM apache/airflow:2.8.0-python3.11
# Install system dependencies
# Install Python packages (airflow, pyspark, pymongo)
# Copy project code and DAGs
# Set AIRFLOW_HOME and PYTHONPATH
```

### Makefile Commands

The `Makefile` provides convenient commands for managing the stack:

| Command | Description |
|---------|-------------|
| `make up` | Start all services |
| `make down` | Stop services (keep volumes) |
| `make down-v` | Stop services and remove volumes |
| `make logs` | Follow all logs |
| `make logs-airflow` | Follow Airflow logs only |
| `make logs-spark` | Follow Spark logs only |
| `make ps` | Show service status |
| `make health` | Check health of all services |
| `make ui` | Display service URLs |
| `make trigger-dag` | Trigger the batch pipeline DAG |
| `make hdfs-ls` | List HDFS directories |
| `make hdfs-create-dirs` | Create required HDFS paths |
| `make mongo-query-views` | Query batch_views collection |
| `make backfill START=... END=...` | Run backfill for date range |
| `make airflow-shell` | Open Airflow container shell |
| `make spark-master-shell` | Open Spark master shell |
| `make mongo-shell` | Open MongoDB shell |

### Development Workflow

1. **Start services**: `make up`
2. **Check health**: `make health`
3. **Create HDFS dirs**: `make hdfs-create-dirs`
4. **Trigger pipeline**: `make trigger-dag`
5. **Monitor execution**:
   - Airflow UI: http://localhost:8080
   - Spark UI: http://localhost:8081
   - HDFS UI: http://localhost:9870
6. **Verify results**: `make mongo-query-views`
7. **Check data**: `make hdfs-ls`
8. **View logs**: `make logs-airflow`

### Cleanup and Reset

```bash
# Stop services but keep data
make down

# Stop services and remove all data
make down-v

# Clean up Docker resources
make clean

# Rebuild images from scratch
make build
```

---

## Configuration

### Spark Configuration (`config/spark_config.yaml`)

```yaml
spark:
  app_name: "batch_layer_processing"
  master: "spark://spark-master:7077"
  
  executor:
    memory: "4g"
    cores: 2
    instances: 10
  
  driver:
    memory: "2g"
    cores: 1
  
  sql:
    adaptive_enabled: true
    coalesce_partitions_enabled: true
    broadcast_timeout: 300
  
  serializer: "org.apache.spark.serializer.KryoSerializer"
```

### HDFS Configuration (`config/hdfs_config.yaml`)

```yaml
hdfs:
  namenode: "hdfs://namenode:9000"
  replication_factor: 3
  block_size: "128m"
  
  paths:
    bronze: "/data/bronze"
    silver: "/data/silver"
    gold: "/data/gold"
  
  retention:
    bronze_days: 90
    silver_days: 730
    gold_days: 1825
```

---

## Next Phase Implementation Tasks

### Phase 2A: Master Dataset Ingestion (Week 3)
- [ ] Implement `master_dataset/ingestion.py`
  - TMDB API client with rate limiting
  - Batch extraction for movies, reviews, people
  - Write raw JSON to HDFS Bronze layer
  - Implement retry logic and error handling

- [ ] Create `master_dataset/schema.py`
  - Define Bronze layer Parquet schemas
  - Validation rules
  - Partition strategies

- [ ] Build `airflow_dags/batch_ingestion_dag.py`
  - 4-hour schedule
  - Parallel extraction tasks
  - Health checks and monitoring
  - Slack/email alerts

### Phase 2B: Silver Layer Transformations (Week 4)
- [ ] Implement `spark_jobs/bronze_to_silver.py`
  - Read Bronze Parquet
  - Deduplication logic
  - Schema validation
  - Data enrichment (genres, cast)

- [ ] Create `spark_jobs/sentiment_batch.py`
  - Historical sentiment analysis
  - VADER or transformer model
  - Batch processing of reviews

- [ ] Build `airflow_dags/batch_transform_dag.py`
  - Trigger after ingestion
  - Spark job orchestration
  - Data quality checks

### Phase 2C: Gold Layer Aggregations (Week 5)
- [ ] Implement `spark_jobs/silver_to_gold.py`
  - Genre aggregations
  - Trending scores with window functions
  - Temporal analysis

- [ ] Create `spark_jobs/actor_networks.py`
  - GraphX-based network analysis
  - Collaboration strength calculations
  - Community detection

- [ ] Build `batch_views/export_to_mongo.py`
  - Gold → MongoDB pipeline
  - Bulk upsert logic
  - Index maintenance

- [ ] Create `airflow_dags/batch_aggregate_dag.py`
  - Trigger after transformations
  - Gold layer processing
  - MongoDB export

### Phase 2D: Testing & Monitoring (Week 5)
- [ ] Write unit tests
  - Test deduplication logic
  - Test aggregation accuracy
  - Test MongoDB export

- [ ] Set up data quality checks
  - Row count validation
  - Schema validation
  - Completeness checks

- [ ] Configure monitoring
  - DAG success/failure rates
  - Spark job duration
  - HDFS storage utilization

---

## Testing Strategy

### Unit Tests
```python
# tests/test_transformations.py
def test_deduplication():
    # Create sample DataFrame with duplicates
    # Run deduplication
    # Assert no duplicates remain
    pass

def test_sentiment_analysis():
    # Sample reviews with known sentiments
    # Run sentiment analysis
    # Assert accuracy > 80%
    pass
```

### Integration Tests
```python
# tests/test_end_to_end.py
def test_bronze_to_silver_pipeline():
    # Write sample Bronze data
    # Run Spark job
    # Validate Silver output
    pass
```

### Data Quality Tests
```python
# tests/test_data_quality.py
def test_completeness():
    # Check for null values in required fields
    pass

def test_schema_compliance():
    # Validate schema matches expected
    pass
```

---

## Monitoring & Alerts

### Key Metrics
- **Batch Job Success Rate**: Target > 99%
- **Processing Time**: < 2 hours per batch
- **Data Quality Score**: > 95% rows passing validation
- **HDFS Storage Growth**: Track and predict capacity

### Alerts
- DAG failure → Slack channel + email
- Data quality below threshold → PagerDuty
- HDFS capacity > 80% → Ops team notification
- Job duration > 3 hours → Warning alert

---

## Troubleshooting

### Common Issues

**Issue**: Spark job OOM errors  
**Solution**: Increase executor memory, reduce partition size

**Issue**: HDFS write failures  
**Solution**: Check namenode health, verify replication factor

**Issue**: Duplicate records in Silver  
**Solution**: Review deduplication logic, check for partition key issues

**Issue**: Slow MongoDB export  
**Solution**: Use bulk writes, create appropriate indexes

---

## References

- [Apache Spark Best Practices](https://spark.apache.org/docs/latest/sql-performance-tuning.html)
- [HDFS Architecture](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [Airflow DAG Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)
- [Lambda Architecture - Batch Layer](http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html)

---

**Next Step**: Proceed to [Speed Layer README](../speed_layer/README.md)
