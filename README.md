# Movie Data Analytics Pipeline - Lambda Architecture

A big data analytics pipeline implementing **Lambda Architecture** with Apache Hadoop, Spark, Kafka, and Cassandra.

## ğŸ—ï¸ Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         TMDB API                    â”‚
                    â”‚    (4 requests/second limit)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚              â”‚
                                 â”‚              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   BATCH LAYER     â”‚  â”‚   SPEED LAYER    â”‚
                    â”‚ (Historical Data) â”‚  â”‚ (Real-time Data) â”‚
                    â”‚                   â”‚  â”‚                  â”‚
                    â”‚ â€¢ HDFS Storage    â”‚  â”‚ â€¢ Kafka Streamingâ”‚
                    â”‚ â€¢ Spark Batch     â”‚  â”‚ â€¢ Cassandra      â”‚
                    â”‚ â€¢ Airflow         â”‚  â”‚ â€¢ Spark Streamingâ”‚
                    â”‚                   â”‚  â”‚                  â”‚
                    â”‚ Every 4 hours     â”‚  â”‚ 5-min windows    â”‚
                    â”‚ Complete accuracy â”‚  â”‚ Low latency      â”‚
                    â”‚ (> 48 hours old)  â”‚  â”‚ (â‰¤ 48 hours old) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚              â”‚
                                 â”‚              â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  SERVING LAYER     â”‚
                              â”‚                    â”‚
                              â”‚ â€¢ MongoDB (merged  â”‚
                              â”‚   batch + speed    â”‚
                              â”‚   views)           â”‚
                              â”‚ â€¢ FastAPI REST API â”‚
                              â”‚ â€¢ Apache Superset  â”‚
                              â”‚ â€¢ Grafana          â”‚
                              â”‚                    â”‚
                              â”‚ Query-time merge   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technology Stack

| Layer | Technology |
|-------|-----------|
| **Batch** | HDFS (Hadoop 3.x), Apache Spark, Apache Airflow |
| **Speed** | Apache Kafka, Apache Cassandra, Spark Streaming |
| **Serving** | MongoDB, FastAPI, Apache Superset, Grafana |
| **Deployment** | Kubernetes, Docker Compose |

## âœ… Implementation To-Do

### Phase 1: Setup & Planning - âœ… COMPLETED
- [x] Lambda Architecture design
- [x] Directory structure (`layers/batch_layer`, `layers/speed_layer`, `layers/serving_layer`)
- [x] Documentation (12+ markdown files)
- [x] Template code for all layers

### Phase 2: Batch Layer - ğŸ”² TODO
- [ ] Deploy HDFS cluster (3 datanodes + namenode)
- [ ] Implement TMDB â†’ HDFS ingestion
- [ ] Create Airflow DAGs (batch orchestration)
- [ ] Bronze â†’ Silver transformations (deduplication, validation)
- [ ] Silver â†’ Gold aggregations (genre, trends, ratings)
- [ ] Sentiment analysis (batch processing)
- [ ] Export batch views to MongoDB

### Phase 3: Speed Layer - ğŸ”² TODO
- [ ] Deploy Kafka cluster (3 brokers + Zookeeper)
- [ ] Deploy Schema Registry (Avro schemas)
- [ ] Implement Kafka producers (real-time)
- [ ] Deploy Cassandra cluster (3 nodes, 48h TTL)
- [ ] Spark Structured Streaming jobs
- [ ] Real-time sentiment analysis
- [ ] Write to Cassandra speed views

### Phase 4: Serving Layer - ğŸ”² TODO
- [ ] Deploy MongoDB (materialized views)
- [ ] Implement FastAPI REST API
- [ ] View merger (batch + speed merge logic)
- [ ] Redis caching layer
- [ ] Apache Superset dashboards
- [ ] Grafana monitoring
- [ ] API authentication & rate limiting

### Phase 5: Integration & Testing - ğŸ”² TODO
- [ ] End-to-end integration
- [ ] 48-hour merge strategy implementation
- [ ] Performance benchmarking
- [ ] Unit & integration tests
- [ ] Data quality validation

### Phase 6: Production Deployment - ğŸ”² TODO
- [ ] Kubernetes manifests (all services)
- [ ] Persistent volumes (HDFS storage)
- [ ] Monitoring & alerting setup
- [ ] Security hardening
- [ ] Deployment automation

## ğŸ“š Documentation

- **Architecture**: `LAMBDA_ARCHITECTURE_V2.md`
- **Roadmap**: `NEXT_PHASE_ROADMAP.md` (14-week plan)
- **Batch Layer**: `layers/batch_layer/README.md`
- **Speed Layer**: `layers/speed_layer/README.md`
- **Serving Layer**: `layers/serving_layer/README.md`
- **Index**: `DOCUMENTATION_INDEX.md`

## ğŸ¯ Current Status

**Phase 1 Complete** âœ…  
Architecture design and documentation ready. Ready to implement Phase 2 (Batch Layer).

---

**License**: MIT | **Support**: [GitHub Issues](https://github.com/auphong2707/movie-data-analysis-pipeline/issues)
