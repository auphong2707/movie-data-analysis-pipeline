# ========================================
# Movie Data Analysis Pipeline - Unified Environment Configuration
# ========================================
# This file combines configuration for BOTH Batch Layer and Speed Layer
# Copy this file to .env and fill in your actual values
# ========================================

# ========================================
# REQUIRED: TMDB API Configuration
# ========================================
# Get your API key from https://www.themoviedb.org/settings/api
TMDB_API_KEY=your_tmdb_api_key_here
TMDB_BASE_URL=https://api.themoviedb.org/3
TMDB_RATE_LIMIT=4.0
TMDB_RETRY_ATTEMPTS=3
TMDB_RETRY_BACKOFF=2.0

# ========================================
# MongoDB Configuration (SHARED - Serving Layer)
# ========================================
# This is the intersection point between Batch and Speed layers
# Both layers write to different collections in the same database
MONGODB_HOST=mongodb
MONGODB_PORT=27017
MONGODB_USERNAME=admin
MONGODB_PASSWORD=password
MONGODB_DATABASE=moviedb
MONGODB_CONNECTION_STRING=mongodb://admin:password@mongodb:27017/moviedb?authSource=admin

# ========================================
# BATCH LAYER: MinIO (S3-compatible storage)
# ========================================
# Used instead of HDFS for simpler local development
S3_ENDPOINT=http://minio:9000
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_BUCKET_BRONZE=bronze-data
S3_BUCKET_SILVER=silver-data
S3_BUCKET_GOLD=gold-data

# ========================================
# BATCH LAYER: Spark Configuration
# ========================================
SPARK_MASTER_URL=local[*]
SPARK_APP_NAME=movie-analytics-batch
SPARK_EXECUTOR_MEMORY=4g
SPARK_EXECUTOR_CORES=2
SPARK_DRIVER_MEMORY=2g

# ========================================
# BATCH LAYER: Airflow Configuration
# ========================================
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
AIRFLOW__WEBSERVER__SECRET_KEY=super_secret_key_12345

# ========================================
# BATCH LAYER: PostgreSQL (Airflow Metadata)
# ========================================
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# ========================================
# BATCH LAYER: Data Retention Policies
# ========================================
BATCH_INTERVAL_HOURS=4
BRONZE_RETENTION_DAYS=90
SILVER_RETENTION_DAYS=730
GOLD_RETENTION_DAYS=1825

# ========================================
# SPEED LAYER: Kafka Configuration (3-broker cluster)
# ========================================
KAFKA_BOOTSTRAP_SERVERS=kafka-1:29092,kafka-2:29092,kafka-3:29092
KAFKA_REPLICATION_FACTOR=3
KAFKA_MIN_INSYNC_REPLICAS=2
SCHEMA_REGISTRY_URL=http://schema-registry:8081

# ========================================
# SPEED LAYER: Zookeeper Configuration
# ========================================
ZOOKEEPER_CLIENT_PORT=2181
ZOOKEEPER_TICK_TIME=2000

# ========================================
# SPEED LAYER: Cassandra Configuration
# ========================================
# 48-hour TTL for speed layer data (Lambda Architecture cutoff)
CASSANDRA_HOSTS=cassandra
CASSANDRA_KEYSPACE=speed_layer
CASSANDRA_REPLICATION_FACTOR=1
CASSANDRA_TTL_HOURS=48

# ========================================
# SPEED LAYER: Sync Configuration
# ========================================
# Cassandra to MongoDB sync intervals
SYNC_INTERVAL=300
CLEANUP_INTERVAL=3600

# ========================================
# Logging Configuration (Both Layers)
# ========================================
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
PYTHONUNBUFFERED=1
